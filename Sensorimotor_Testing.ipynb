{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOBtxa+P+eXEu48sJJ6zuAA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ppfenninger/Sensorimotor_Learning_Final/blob/main/Sensorimotor_Testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ruqTIwpD5vnR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00e4cce8-d52d-4ff8-960c-cdb183bcf667"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.0.0+cu118\n",
            "Uninstalling torch-2.0.0+cu118:\n",
            "  Successfully uninstalled torch-2.0.0+cu118\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch==1.12.0\n",
            "  Downloading torch-1.12.0-cp310-cp310-manylinux1_x86_64.whl (776.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.12.0) (4.5.0)\n",
            "Installing collected packages: torch\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.15.1+cu118 requires torch==2.0.0, but you have torch 1.12.0 which is incompatible.\n",
            "torchtext 0.15.1 requires torch==2.0.0, but you have torch 1.12.0 which is incompatible.\n",
            "torchdata 0.6.0 requires torch==2.0.0, but you have torch 1.12.0 which is incompatible.\n",
            "torchaudio 2.0.1+cu118 requires torch==2.0.0, but you have torch 1.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.12.0\n"
          ]
        }
      ],
      "source": [
        "## Installation\n",
        "!pip install pybullet > /dev/null 2>&1\n",
        "!pip install git+https://github.com/taochenshh/easyrl.git > /dev/null 2>&1\n",
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "!pip install git+https://github.com/ppfenninger/airobot.git > /dev/null 2>&1\n",
        "# !pip install git+https://github.com/ppfenninger/Sensorimotor_Learning_Final.git > /dev/null 2>&1\n",
        "!pip uninstall torch -y\n",
        "!pip install torch==1.12.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import gym\n",
        "import pprint\n",
        "import time\n",
        "import pybullet as p\n",
        "import pybullet_data as pd\n",
        "import pybullet_envs\n",
        "import airobot as ar\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from typing import Any\n",
        "from matplotlib import animation\n",
        "from IPython.display import HTML\n",
        "from matplotlib import pylab\n",
        "from dataclasses import dataclass\n",
        "from gym import spaces\n",
        "from gym.envs.registration import registry, register\n",
        "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
        "from tqdm.notebook import tqdm\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from pathlib import Path\n",
        "from copy import deepcopy\n",
        "from itertools import count\n",
        "from easyrl.agents.ppo_agent import PPOAgent\n",
        "from easyrl.utils.common import save_traj\n",
        "from easyrl.configs import cfg\n",
        "from easyrl.configs import set_config\n",
        "from easyrl.configs.basic_config import BasicConfig\n",
        "from easyrl.configs.command_line import cfg_from_cmd\n",
        "from easyrl.engine.ppo_engine import PPOEngine\n",
        "from easyrl.models.categorical_policy import CategoricalPolicy\n",
        "from easyrl.models.diag_gaussian_policy import DiagGaussianPolicy\n",
        "from easyrl.models.mlp import MLP\n",
        "from easyrl.models.value_net import ValueNet\n",
        "from easyrl.agents.base_agent import BaseAgent\n",
        "from easyrl.utils.torch_util import DictDataset\n",
        "from easyrl.utils.torch_util import load_state_dict\n",
        "from easyrl.utils.torch_util import load_torch_model\n",
        "from easyrl.runner.nstep_runner import EpisodicRunner\n",
        "from easyrl.utils.torch_util import save_model\n",
        "from easyrl.utils.torch_util import action_entropy\n",
        "from easyrl.utils.torch_util import action_from_dist\n",
        "from easyrl.utils.torch_util import action_log_prob\n",
        "from easyrl.utils.torch_util import clip_grad\n",
        "from easyrl.utils.common import set_random_seed\n",
        "from easyrl.utils.gym_util import make_vec_env\n",
        "from easyrl.utils.common import load_from_json\n",
        "from easyrl.utils.torch_util import freeze_model\n",
        "from easyrl.utils.torch_util import move_to\n",
        "from easyrl.utils.torch_util import torch_float\n",
        "from easyrl.utils.torch_util import torch_to_np\n",
        "from base64 import b64encode\n",
        "from IPython import display as ipythondisplay"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qE3jrtj51tg",
        "outputId": "01d743f6-60ca-46f2-deb6-2976661c0ce2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:440: UserWarning: \u001b[33mWARN: The `registry.env_specs` property along with `EnvSpecTree` is deprecated. Please use `registry` directly as a dictionary instead.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/easyrl/envs/shmem_vec_env.py:23: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  np.bool: ctypes.c_bool}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del sys.modules[\"de_agent\"]\n",
        "del sys.modules[\"de_runner\"]\n",
        "del sys.modules[\"utils\"]\n",
        "del sys.modules[\"de_env\"]\n",
        "del sys.modules[\"de_engine\"]\n",
        "\n",
        "# install our library\n",
        "!rm Sensorimotor_Learning_Final -r\n",
        "!git clone -b testing https://github.com/ppfenninger/Sensorimotor_Learning_Final.git\n",
        "import sys\n",
        "sys.path.insert(0, './Sensorimotor_Learning_Final/deepexploration/')\n",
        "import de_agent\n",
        "from de_agent import DeepExplorationAgent\n",
        "# import de_engine\n",
        "import de_runner # this should work once everything compiles\n",
        "from de_runner import DeepExplorationRunner\n",
        "import utils\n",
        "from utils import eval_agent, load_expert_agent, create_actor, create_critic\n",
        "\n",
        "import de_env\n",
        "from de_env import URRobotPusherGym\n",
        "\n",
        "import de_engine\n",
        "from de_engine import DeepExplorationEngine\n",
        "\n",
        "module_name = __name__\n",
        "\n",
        "env_name = 'URPusher-v1'\n",
        "if env_name in registry.env_specs:\n",
        "    del registry.env_specs[env_name]\n",
        "register(\n",
        "    id=env_name,\n",
        "    entry_point=f'{module_name}:URRobotPusherGym',\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFOrlFpX53Q6",
        "outputId": "9269a932-ca8c-446b-8fdb-40d7fc416ab5"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Sensorimotor_Learning_Final'...\n",
            "remote: Enumerating objects: 274, done.\u001b[K\n",
            "remote: Counting objects: 100% (91/91), done.\u001b[K\n",
            "remote: Compressing objects: 100% (44/44), done.\u001b[K\n",
            "remote: Total 274 (delta 71), reused 56 (delta 46), pack-reused 183\u001b[K\n",
            "Receiving objects: 100% (274/274), 150.91 KiB | 16.77 MiB/s, done.\n",
            "Resolving deltas: 100% (143/143), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "gmdo8YtM-Rsg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DEConfig(BasicConfig):\n",
        "    num_traj = 1\n",
        "\n",
        "def set_configs(exp_name='de'):\n",
        "    cfg.alg = DEConfig()\n",
        "    cfg.alg.seed = 2957 #seed\n",
        "    cfg.alg.num_envs = 1\n",
        "    cfg.alg.episode_steps = 150\n",
        "    cfg.alg.max_steps = 600000\n",
        "    cfg.alg.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    cfg.alg.env_name = 'URPusher-v1'\n",
        "    cfg.alg.save_dir = Path.cwd().absolute().joinpath('data').as_posix()\n",
        "    cfg.alg.save_dir += f'/{exp_name}'\n",
        "    cfg.alg.policy_lr: float = 3e-4\n",
        "    cfg.alg.value_lr: float = 1e-3\n",
        "    cfg.alg.linear_decay_lr: bool = False\n",
        "    cfg.alg.max_decay_steps: int = 1e6\n",
        "    cfg.alg.num_envs: int = 8\n",
        "    cfg.alg.eval_num_envs: int = None\n",
        "    cfg.alg.opt_epochs: int = 10\n",
        "    cfg.alg.normalize_adv: bool = True\n",
        "    cfg.alg.clip_vf_loss: bool = False\n",
        "    cfg.alg.vf_loss_type: str = 'mse'\n",
        "    cfg.alg.vf_coef: float = 0.5\n",
        "    cfg.alg.ent_coef: float = 0.01\n",
        "    cfg.alg.clip_range: float = 0.2\n",
        "    cfg.alg.linear_decay_clip_range: bool = False\n",
        "    cfg.alg.gae_lambda: float = 0.95\n",
        "    cfg.alg.rew_discount: float = 0.99\n",
        "    cfg.alg.use_amsgrad: bool = True\n",
        "    cfg.alg.sgd: bool = False\n",
        "    cfg.alg.momentum: float = 0.00\n",
        "    cfg.alg.tanh_on_dist: bool = False\n",
        "    cfg.alg.std_cond_in: bool = False\n",
        "    cfg.alg.log_interval = 5\n",
        "    setattr(cfg.alg, 'diff_cfg', dict(save_dir=cfg.alg.save_dir))\n",
        "\n",
        "    print(f'====================================')\n",
        "    print(f'      Device:{cfg.alg.device}')\n",
        "    print(f'====================================')"
      ],
      "metadata": {
        "id": "ygOfylf56eXl"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Runner Tests\n",
        "set_configs()\n",
        "env = URRobotPusherGym(max_episode_length=30)\n",
        "\n",
        "critics = []\n",
        "for index in range(4):\n",
        "  ob_size = env.observation_space.shape[0]\n",
        "  critic_body = MLP(input_size=ob_size,\n",
        "                     hidden_sizes=[64],\n",
        "                     output_size=64,\n",
        "                     hidden_act=nn.Tanh,\n",
        "                     output_act=nn.Tanh)\n",
        "  critic = ValueNet(critic_body, in_features=64)\n",
        "  critics.append(critic)\n",
        "\n",
        "actor = create_actor(env=env)\n",
        "agent = DeepExplorationAgent(actor=actor, critics=critics, env=env)\n",
        "runner = DeepExplorationRunner(agent=agent, env=env)\n",
        "\n",
        "# traj = runner(time_steps=cfg.alg.episode_steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJ-EgxnK6vPb",
        "outputId": "e80d813d-249c-4858-8724-97fa41f5e6f2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================\n",
            "      Device:cuda\n",
            "====================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/spaces/box.py:128: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i have this many people telling me what to do 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_de(max_steps=200000):\n",
        "    set_configs()\n",
        "    cfg.alg.num_envs = 1\n",
        "    cfg.alg.episode_steps = 100\n",
        "    cfg.alg.max_steps = max_steps\n",
        "    cfg.alg.deque_size = 20\n",
        "    cfg.alg.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    cfg.alg.env_name = 'URPusher-v1'\n",
        "    cfg.alg.save_dir = Path.cwd().absolute().joinpath('data').as_posix()\n",
        "    cfg.alg.save_dir += '/'\n",
        "    cfg.alg.save_dir += 'push'\n",
        "    setattr(cfg.alg, 'diff_cfg', dict(save_dir=cfg.alg.save_dir))\n",
        "\n",
        "    print(f'====================================')\n",
        "    print(f'      Device:{cfg.alg.device}')\n",
        "    print(f'      Total number of steps:{cfg.alg.max_steps}')\n",
        "    print(f'====================================')\n",
        "\n",
        "    set_random_seed(cfg.alg.seed)\n",
        "    env_kwargs=dict()\n",
        "    env = make_vec_env(cfg.alg.env_name,\n",
        "                       cfg.alg.num_envs,\n",
        "                       seed=cfg.alg.seed,\n",
        "                       env_kwargs=env_kwargs)\n",
        "    env.reset()\n",
        "    ob_size = env.observation_space.shape[0]\n",
        "\n",
        "    actor_body = MLP(input_size=ob_size,\n",
        "                     hidden_sizes=[64],\n",
        "                     output_size=64,\n",
        "                     hidden_act=nn.Tanh,\n",
        "                     output_act=nn.Tanh)\n",
        "\n",
        "    critic_body = MLP(input_size=ob_size,\n",
        "                     hidden_sizes=[64],\n",
        "                     output_size=64,\n",
        "                     hidden_act=nn.Tanh,\n",
        "                     output_act=nn.Tanh)\n",
        "  \n",
        "    if isinstance(env.action_space, gym.spaces.Discrete):\n",
        "        act_size = env.action_space.n\n",
        "        actor = CategoricalPolicy(actor_body,\n",
        "                                 in_features=64,\n",
        "                                 action_dim=act_size)\n",
        "        \n",
        "    elif isinstance(env.action_space, gym.spaces.Box):\n",
        "        act_size = env.action_space.shape[0]\n",
        "        actor = DiagGaussianPolicy(actor_body,\n",
        "                                   in_features=64,\n",
        "                                   action_dim=act_size,\n",
        "                                   tanh_on_dist=cfg.alg.tanh_on_dist,\n",
        "                                   std_cond_in=cfg.alg.std_cond_in)\n",
        "    else:\n",
        "        raise TypeError(f'Unknown action space type: {env.action_space}')\n",
        "\n",
        "    critics = [] # ValueNet(critic_body, in_features=64) # TODO: get critics\n",
        "\n",
        "    for critic in range(2):\n",
        "      critics.append(create_critic(env))\n",
        "\n",
        "\n",
        "    agent = DeepExplorationAgent(actor=actor, critics=critics, env=env)\n",
        "    runner = DeepExplorationRunner(agent=agent, env=env)\n",
        "    engine = DeepExplorationEngine(agent=agent, runner=runner, env=env)\n",
        "    engine.train()\n",
        "    stat_info, raw_traj_info = engine.eval(render=False, save_eval_traj=True, eval_num=1, sleep_time=0.0)\n",
        "    pprint.pprint(stat_info)\n",
        "    return cfg.alg.save_dir"
      ],
      "metadata": {
        "id": "L7VVr1sV2T_P"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "5Z1xlQ5V-WDr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "saved_dir_pusher = train_de(max_steps = 100000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWzzqcui5mAL",
        "outputId": "950eafea-6445-4f31-95b0-f70eef890022"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[INFO]\u001b[0m[2023-05-07 17:11:22]: \u001b[32mCreating 1 environments.\u001b[0m\n",
            "INFO:EasyRL:Creating 1 environments.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================\n",
            "      Device:cuda\n",
            "====================================\n",
            "====================================\n",
            "      Device:cuda\n",
            "      Total number of steps:100000\n",
            "====================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m[ERROR]\u001b[0m[2023-05-07 17:11:23]: \u001b[31mNot a valid git repo: /usr/local/lib/python3.10/dist-packages\u001b[0m\n",
            "ERROR:EasyRL:Not a valid git repo: /usr/local/lib/python3.10/dist-packages\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i have this many people telling me what to do 2\n",
            "iter: 0\n",
            "We are done! 29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[INFO]\u001b[0m[2023-05-07 17:11:23]: \u001b[32mExploration steps: 0\u001b[0m\n",
            "INFO:EasyRL:Exploration steps: 0\n",
            "\u001b[32m[INFO]\u001b[0m[2023-05-07 17:11:23]: \u001b[32mSaving checkpoint: /content/data/push/seed_2957/model/ckpt_000000000000.pt.\u001b[0m\n",
            "INFO:EasyRL:Saving checkpoint: /content/data/push/seed_2957/model/ckpt_000000000000.pt.\n",
            "\u001b[32m[INFO]\u001b[0m[2023-05-07 17:11:23]: \u001b[32mSaving checkpoint: /content/data/push/seed_2957/model/model_best.pt.\u001b[0m\n",
            "INFO:EasyRL:Saving checkpoint: /content/data/push/seed_2957/model/model_best.pt.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We are done! 29\n",
            "iter: 1\n",
            "iter: 2\n",
            "iter: 3\n",
            "iter: 4\n",
            "iter: 5\n",
            "iter: 6\n",
            "iter: 7\n",
            "iter: 8\n",
            "iter: 9\n",
            "iter: 10\n",
            "iter: 11\n",
            "iter: 12\n",
            "iter: 13\n",
            "iter: 14\n",
            "iter: 15\n",
            "iter: 16\n",
            "iter: 17\n",
            "iter: 18\n",
            "iter: 19\n",
            "iter: 20\n",
            "iter: 21\n",
            "iter: 22\n",
            "iter: 23\n",
            "iter: 24\n",
            "iter: 25\n",
            "iter: 26\n",
            "iter: 27\n",
            "iter: 28\n",
            "iter: 29\n",
            "iter: 30\n",
            "iter: 31\n",
            "iter: 32\n",
            "iter: 33\n",
            "iter: 34\n",
            "iter: 35\n",
            "iter: 36\n",
            "iter: 37\n",
            "iter: 38\n",
            "iter: 39\n",
            "iter: 40\n",
            "iter: 41\n",
            "iter: 42\n",
            "iter: 43\n",
            "iter: 44\n",
            "iter: 45\n",
            "iter: 46\n",
            "iter: 47\n",
            "iter: 48\n",
            "iter: 49\n",
            "iter: 50\n",
            "iter: 51\n",
            "iter: 52\n",
            "iter: 53\n",
            "iter: 54\n",
            "iter: 55\n",
            "iter: 56\n",
            "iter: 57\n",
            "iter: 58\n",
            "iter: 59\n",
            "iter: 60\n",
            "iter: 61\n",
            "iter: 62\n",
            "iter: 63\n",
            "iter: 64\n",
            "iter: 65\n",
            "iter: 66\n",
            "iter: 67\n",
            "iter: 68\n",
            "iter: 69\n",
            "iter: 70\n",
            "iter: 71\n",
            "iter: 72\n",
            "iter: 73\n",
            "iter: 74\n",
            "iter: 75\n",
            "iter: 76\n",
            "iter: 77\n",
            "iter: 78\n",
            "iter: 79\n",
            "iter: 80\n",
            "iter: 81\n",
            "iter: 82\n",
            "iter: 83\n",
            "iter: 84\n",
            "iter: 85\n",
            "iter: 86\n",
            "iter: 87\n",
            "iter: 88\n",
            "iter: 89\n",
            "iter: 90\n",
            "iter: 91\n",
            "iter: 92\n",
            "iter: 93\n",
            "iter: 94\n",
            "iter: 95\n",
            "iter: 96\n",
            "iter: 97\n",
            "iter: 98\n",
            "iter: 99\n",
            "iter: 100\n",
            "We are done! 29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[INFO]\u001b[0m[2023-05-07 17:14:22]: \u001b[32mExploration steps: 10000\u001b[0m\n",
            "INFO:EasyRL:Exploration steps: 10000\n",
            "\u001b[32m[INFO]\u001b[0m[2023-05-07 17:14:22]: \u001b[32mSaving checkpoint: /content/data/push/seed_2957/model/ckpt_000000010000.pt.\u001b[0m\n",
            "INFO:EasyRL:Saving checkpoint: /content/data/push/seed_2957/model/ckpt_000000010000.pt.\n",
            "\u001b[32m[INFO]\u001b[0m[2023-05-07 17:14:22]: \u001b[32mSaving checkpoint: /content/data/push/seed_2957/model/model_best.pt.\u001b[0m\n",
            "INFO:EasyRL:Saving checkpoint: /content/data/push/seed_2957/model/model_best.pt.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We are done! 29\n",
            "iter: 101\n",
            "iter: 102\n",
            "iter: 103\n",
            "iter: 104\n",
            "iter: 105\n",
            "iter: 106\n",
            "iter: 107\n",
            "iter: 108\n",
            "iter: 109\n",
            "iter: 110\n",
            "iter: 111\n",
            "iter: 112\n",
            "iter: 113\n",
            "iter: 114\n",
            "iter: 115\n",
            "iter: 116\n",
            "iter: 117\n",
            "iter: 118\n",
            "iter: 119\n",
            "iter: 120\n",
            "iter: 121\n",
            "iter: 122\n",
            "iter: 123\n",
            "iter: 124\n",
            "iter: 125\n",
            "iter: 126\n",
            "iter: 127\n",
            "iter: 128\n",
            "iter: 129\n",
            "iter: 130\n",
            "iter: 131\n",
            "iter: 132\n",
            "iter: 133\n",
            "iter: 134\n",
            "iter: 135\n",
            "iter: 136\n",
            "iter: 137\n",
            "iter: 138\n",
            "iter: 139\n",
            "iter: 140\n",
            "iter: 141\n",
            "iter: 142\n",
            "iter: 143\n",
            "iter: 144\n",
            "iter: 145\n",
            "iter: 146\n",
            "iter: 147\n",
            "iter: 148\n",
            "iter: 149\n",
            "iter: 150\n",
            "iter: 151\n",
            "iter: 152\n",
            "iter: 153\n",
            "iter: 154\n",
            "iter: 155\n",
            "iter: 156\n",
            "iter: 157\n",
            "iter: 158\n",
            "iter: 159\n",
            "iter: 160\n",
            "iter: 161\n",
            "iter: 162\n",
            "iter: 163\n",
            "iter: 164\n",
            "iter: 165\n",
            "iter: 166\n",
            "iter: 167\n",
            "iter: 168\n",
            "iter: 169\n",
            "iter: 170\n",
            "iter: 171\n",
            "iter: 172\n",
            "iter: 173\n",
            "iter: 174\n",
            "iter: 175\n",
            "iter: 176\n",
            "iter: 177\n",
            "iter: 178\n",
            "iter: 179\n",
            "iter: 180\n",
            "iter: 181\n",
            "iter: 182\n",
            "iter: 183\n",
            "iter: 184\n",
            "iter: 185\n",
            "iter: 186\n",
            "iter: 187\n",
            "iter: 188\n",
            "iter: 189\n",
            "iter: 190\n",
            "iter: 191\n",
            "iter: 192\n",
            "iter: 193\n",
            "iter: 194\n",
            "iter: 195\n",
            "iter: 196\n",
            "iter: 197\n",
            "iter: 198\n",
            "iter: 199\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[INFO]\u001b[0m[2023-05-07 17:17:26]: \u001b[32mExploration steps: 20000\u001b[0m\n",
            "INFO:EasyRL:Exploration steps: 20000\n",
            "\u001b[32m[INFO]\u001b[0m[2023-05-07 17:17:26]: \u001b[32mSaving checkpoint: /content/data/push/seed_2957/model/ckpt_000000020000.pt.\u001b[0m\n",
            "INFO:EasyRL:Saving checkpoint: /content/data/push/seed_2957/model/ckpt_000000020000.pt.\n",
            "\u001b[32m[INFO]\u001b[0m[2023-05-07 17:17:26]: \u001b[32mSaving checkpoint: /content/data/push/seed_2957/model/model_best.pt.\u001b[0m\n",
            "INFO:EasyRL:Saving checkpoint: /content/data/push/seed_2957/model/model_best.pt.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter: 200\n",
            "We are done! 29\n",
            "We are done! 29\n",
            "iter: 201\n",
            "iter: 202\n",
            "iter: 203\n",
            "iter: 204\n",
            "iter: 205\n",
            "iter: 206\n",
            "iter: 207\n",
            "iter: 208\n",
            "iter: 209\n",
            "iter: 210\n",
            "iter: 211\n",
            "iter: 212\n",
            "iter: 213\n",
            "iter: 214\n",
            "iter: 215\n",
            "iter: 216\n",
            "iter: 217\n",
            "iter: 218\n",
            "iter: 219\n",
            "iter: 220\n",
            "iter: 221\n",
            "iter: 222\n",
            "iter: 223\n",
            "iter: 224\n",
            "iter: 225\n",
            "iter: 226\n",
            "iter: 227\n",
            "iter: 228\n",
            "iter: 229\n",
            "iter: 230\n",
            "iter: 231\n",
            "iter: 232\n",
            "iter: 233\n",
            "iter: 234\n",
            "iter: 235\n",
            "iter: 236\n",
            "iter: 237\n",
            "iter: 238\n",
            "iter: 239\n",
            "iter: 240\n",
            "iter: 241\n",
            "iter: 242\n",
            "iter: 243\n",
            "iter: 244\n",
            "iter: 245\n",
            "iter: 246\n",
            "iter: 247\n",
            "iter: 248\n",
            "iter: 249\n",
            "iter: 250\n",
            "iter: 251\n",
            "iter: 252\n",
            "iter: 253\n",
            "iter: 254\n",
            "iter: 255\n",
            "iter: 256\n",
            "iter: 257\n",
            "iter: 258\n",
            "iter: 259\n",
            "iter: 260\n",
            "iter: 261\n",
            "iter: 262\n",
            "iter: 263\n",
            "iter: 264\n",
            "iter: 265\n",
            "iter: 266\n",
            "iter: 267\n",
            "iter: 268\n",
            "iter: 269\n",
            "iter: 270\n",
            "iter: 271\n",
            "iter: 272\n",
            "iter: 273\n",
            "iter: 274\n",
            "iter: 275\n",
            "iter: 276\n",
            "iter: 277\n",
            "iter: 278\n",
            "iter: 279\n",
            "iter: 280\n",
            "iter: 281\n",
            "iter: 282\n",
            "iter: 283\n",
            "iter: 284\n",
            "iter: 285\n",
            "iter: 286\n",
            "iter: 287\n",
            "iter: 288\n",
            "iter: 289\n",
            "iter: 290\n",
            "iter: 291\n",
            "iter: 292\n",
            "iter: 293\n",
            "iter: 294\n",
            "iter: 295\n",
            "iter: 296\n",
            "iter: 297\n",
            "iter: 298\n",
            "iter: 299\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[INFO]\u001b[0m[2023-05-07 17:20:22]: \u001b[32mExploration steps: 30000\u001b[0m\n",
            "INFO:EasyRL:Exploration steps: 30000\n",
            "\u001b[32m[INFO]\u001b[0m[2023-05-07 17:20:22]: \u001b[32mSaving checkpoint: /content/data/push/seed_2957/model/ckpt_000000030000.pt.\u001b[0m\n",
            "INFO:EasyRL:Saving checkpoint: /content/data/push/seed_2957/model/ckpt_000000030000.pt.\n",
            "\u001b[32m[INFO]\u001b[0m[2023-05-07 17:20:22]: \u001b[32mSaving checkpoint: /content/data/push/seed_2957/model/model_best.pt.\u001b[0m\n",
            "INFO:EasyRL:Saving checkpoint: /content/data/push/seed_2957/model/model_best.pt.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter: 300\n",
            "We are done! 29\n",
            "We are done! 29\n",
            "iter: 301\n",
            "iter: 302\n",
            "iter: 303\n",
            "iter: 304\n",
            "iter: 305\n",
            "iter: 306\n",
            "iter: 307\n",
            "iter: 308\n",
            "iter: 309\n",
            "iter: 310\n",
            "iter: 311\n",
            "iter: 312\n",
            "iter: 313\n",
            "iter: 314\n",
            "iter: 315\n",
            "iter: 316\n",
            "iter: 317\n",
            "iter: 318\n",
            "iter: 319\n",
            "iter: 320\n",
            "iter: 321\n",
            "iter: 322\n",
            "iter: 323\n",
            "iter: 324\n",
            "iter: 325\n",
            "iter: 326\n",
            "iter: 327\n",
            "iter: 328\n",
            "iter: 329\n",
            "iter: 330\n",
            "iter: 331\n",
            "iter: 332\n",
            "iter: 333\n",
            "iter: 334\n",
            "iter: 335\n",
            "iter: 336\n",
            "iter: 337\n",
            "iter: 338\n",
            "iter: 339\n",
            "iter: 340\n",
            "iter: 341\n",
            "iter: 342\n",
            "iter: 343\n",
            "iter: 344\n",
            "iter: 345\n",
            "iter: 346\n",
            "iter: 347\n",
            "iter: 348\n",
            "iter: 349\n",
            "iter: 350\n",
            "iter: 351\n",
            "iter: 352\n",
            "iter: 353\n",
            "iter: 354\n",
            "iter: 355\n",
            "iter: 356\n",
            "iter: 357\n",
            "iter: 358\n",
            "iter: 359\n",
            "iter: 360\n",
            "iter: 361\n",
            "iter: 362\n",
            "iter: 363\n",
            "iter: 364\n",
            "iter: 365\n",
            "iter: 366\n",
            "iter: 367\n",
            "iter: 368\n",
            "iter: 369\n",
            "iter: 370\n",
            "iter: 371\n",
            "iter: 372\n",
            "iter: 373\n",
            "iter: 374\n",
            "iter: 375\n",
            "iter: 376\n",
            "iter: 377\n",
            "iter: 378\n",
            "iter: 379\n",
            "iter: 380\n",
            "iter: 381\n",
            "iter: 382\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(saved_dir_pusher)\n",
        "\n",
        "def read_tf_log(log_dir):\n",
        "    log_dir = Path(log_dir)\n",
        "    log_files = list(log_dir.glob(f'**/events.*'))\n",
        "    print(log_files)\n",
        "    if len(log_files) < 1:\n",
        "        return None\n",
        "    log_file = log_files[0]\n",
        "    event_acc = EventAccumulator(log_file.as_posix())\n",
        "    event_acc.Reload()\n",
        "    tags = event_acc.Tags()\n",
        "    try:\n",
        "        scalar_success = event_acc.Scalars('train/episode_success')\n",
        "        success_rate = [x.value for x in scalar_success]\n",
        "        steps = [x.step for x in scalar_success]\n",
        "        scalar_return = event_acc.Scalars('train/episode_return/mean')\n",
        "        returns = [x.value for x in scalar_return]\n",
        "    except:\n",
        "        return None\n",
        "    return steps, returns, success_rate\n",
        "\n",
        "steps, returns, success_rates = read_tf_log(saved_dir_pusher)"
      ],
      "metadata": {
        "id": "bzJaSzuzlRSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(steps, returns)\n",
        "print(returns)\n",
        "print(steps)\n",
        "print(success_rates)"
      ],
      "metadata": {
        "id": "UCm8i5t2Jfx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "eFF3Pnnp5VqB"
      }
    }
  ]
}