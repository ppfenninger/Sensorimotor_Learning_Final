{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP3oGqAWNX7qk5r/CaU1N7H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ppfenninger/Sensorimotor_Learning_Final/blob/main/Sensorimotor_Testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ruqTIwpD5vnR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17c313d5-4e4e-4c7e-fd33-329abeaeb606"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "## Installation\n",
        "!pip install pybullet > /dev/null 2>&1\n",
        "!pip install git+https://github.com/taochenshh/easyrl.git > /dev/null 2>&1\n",
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "!pip install git+https://github.com/ppfenninger/airobot.git > /dev/null 2>&1\n",
        "# !pip install git+https://github.com/ppfenninger/Sensorimotor_Learning_Final.git > /dev/null 2>&1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import gym\n",
        "import pprint\n",
        "import time\n",
        "import pybullet as p\n",
        "import pybullet_data as pd\n",
        "import pybullet_envs\n",
        "import airobot as ar\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from typing import Any\n",
        "from matplotlib import animation\n",
        "from IPython.display import HTML\n",
        "from matplotlib import pylab\n",
        "from dataclasses import dataclass\n",
        "from gym import spaces\n",
        "from gym.envs.registration import registry, register\n",
        "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
        "from tqdm.notebook import tqdm\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from pathlib import Path\n",
        "from copy import deepcopy\n",
        "from itertools import count\n",
        "from easyrl.agents.ppo_agent import PPOAgent\n",
        "from easyrl.utils.common import save_traj\n",
        "from easyrl.configs import cfg\n",
        "from easyrl.configs import set_config\n",
        "from easyrl.configs.command_line import cfg_from_cmd\n",
        "from easyrl.engine.ppo_engine import PPOEngine\n",
        "from easyrl.models.categorical_policy import CategoricalPolicy\n",
        "from easyrl.models.diag_gaussian_policy import DiagGaussianPolicy\n",
        "from easyrl.models.mlp import MLP\n",
        "from easyrl.models.value_net import ValueNet\n",
        "from easyrl.agents.base_agent import BaseAgent\n",
        "from easyrl.utils.torch_util import DictDataset\n",
        "from easyrl.utils.torch_util import load_state_dict\n",
        "from easyrl.utils.torch_util import load_torch_model\n",
        "from easyrl.runner.nstep_runner import EpisodicRunner\n",
        "from easyrl.utils.torch_util import save_model\n",
        "from easyrl.utils.torch_util import action_entropy\n",
        "from easyrl.utils.torch_util import action_from_dist\n",
        "from easyrl.utils.torch_util import action_log_prob\n",
        "from easyrl.utils.torch_util import clip_grad\n",
        "from easyrl.utils.common import set_random_seed\n",
        "from easyrl.utils.gym_util import make_vec_env\n",
        "from easyrl.utils.common import load_from_json\n",
        "from easyrl.utils.torch_util import freeze_model\n",
        "from easyrl.utils.torch_util import move_to\n",
        "from easyrl.utils.torch_util import torch_float\n",
        "from easyrl.utils.torch_util import torch_to_np\n",
        "from base64 import b64encode\n",
        "from IPython import display as ipythondisplay"
      ],
      "metadata": {
        "id": "_qE3jrtj51tg"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# del sys.modules[\"de_agent\"]\n",
        "# del sys.modules[\"de_runner\"]\n",
        "# del sys.modules[\"utils\"]\n",
        "# del sys.modules[\"de_env\"]\n",
        "\n",
        "# install our library\n",
        "!rm Sensorimotor_Learning_Final -r\n",
        "!git clone -b testing https://github.com/ppfenninger/Sensorimotor_Learning_Final.git\n",
        "import sys\n",
        "sys.path.insert(0, './Sensorimotor_Learning_Final/deepexploration/')\n",
        "import de_agent\n",
        "from de_agent import DeepExplorationAgent\n",
        "# import de_engine\n",
        "import de_runner # this should work once everything compiles\n",
        "from de_runner import DeepExplorationRunner\n",
        "import utils\n",
        "from utils import eval_agent, load_expert_agent, create_actor, create_critic\n",
        "\n",
        "import de_env\n",
        "from de_env import URRobotPusherGym\n",
        "\n",
        "import de_engine\n",
        "from de_engine import DeepExplorationEngine\n",
        "\n",
        "module_name = __name__\n",
        "\n",
        "env_name = 'URPusher-v1'\n",
        "if env_name in registry.env_specs:\n",
        "    del registry.env_specs[env_name]\n",
        "register(\n",
        "    id=env_name,\n",
        "    entry_point=f'{module_name}:URRobotPusherGym',\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "aFOrlFpX53Q6",
        "outputId": "e7523f22-1c24-49cb-d03e-881eeaec1c79"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Sensorimotor_Learning_Final'...\n",
            "remote: Enumerating objects: 215, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/61)\u001b[K\rremote: Counting objects:   3% (2/61)\u001b[K\rremote: Counting objects:   4% (3/61)\u001b[K\rremote: Counting objects:   6% (4/61)\u001b[K\rremote: Counting objects:   8% (5/61)\u001b[K\rremote: Counting objects:   9% (6/61)\u001b[K\rremote: Counting objects:  11% (7/61)\u001b[K\rremote: Counting objects:  13% (8/61)\u001b[K\rremote: Counting objects:  14% (9/61)\u001b[K\rremote: Counting objects:  16% (10/61)\u001b[K\rremote: Counting objects:  18% (11/61)\u001b[K\rremote: Counting objects:  19% (12/61)\u001b[K\rremote: Counting objects:  21% (13/61)\u001b[K\rremote: Counting objects:  22% (14/61)\u001b[K\rremote: Counting objects:  24% (15/61)\u001b[K\rremote: Counting objects:  26% (16/61)\u001b[K\rremote: Counting objects:  27% (17/61)\u001b[K\rremote: Counting objects:  29% (18/61)\u001b[K\rremote: Counting objects:  31% (19/61)\u001b[K\rremote: Counting objects:  32% (20/61)\u001b[K\rremote: Counting objects:  34% (21/61)\u001b[K\rremote: Counting objects:  36% (22/61)\u001b[K\rremote: Counting objects:  37% (23/61)\u001b[K\rremote: Counting objects:  39% (24/61)\u001b[K\rremote: Counting objects:  40% (25/61)\u001b[K\rremote: Counting objects:  42% (26/61)\u001b[K\rremote: Counting objects:  44% (27/61)\u001b[K\rremote: Counting objects:  45% (28/61)\u001b[K\rremote: Counting objects:  47% (29/61)\u001b[K\rremote: Counting objects:  49% (30/61)\u001b[K\rremote: Counting objects:  50% (31/61)\u001b[K\rremote: Counting objects:  52% (32/61)\u001b[K\rremote: Counting objects:  54% (33/61)\u001b[K\rremote: Counting objects:  55% (34/61)\u001b[K\rremote: Counting objects:  57% (35/61)\u001b[K\rremote: Counting objects:  59% (36/61)\u001b[K\rremote: Counting objects:  60% (37/61)\u001b[K\rremote: Counting objects:  62% (38/61)\u001b[K\rremote: Counting objects:  63% (39/61)\u001b[K\rremote: Counting objects:  65% (40/61)\u001b[K\rremote: Counting objects:  67% (41/61)\u001b[K\rremote: Counting objects:  68% (42/61)\u001b[K\rremote: Counting objects:  70% (43/61)\u001b[K\rremote: Counting objects:  72% (44/61)\u001b[K\rremote: Counting objects:  73% (45/61)\u001b[K\rremote: Counting objects:  75% (46/61)\u001b[K\rremote: Counting objects:  77% (47/61)\u001b[K\rremote: Counting objects:  78% (48/61)\u001b[K\rremote: Counting objects:  80% (49/61)\u001b[K\rremote: Counting objects:  81% (50/61)\u001b[K\rremote: Counting objects:  83% (51/61)\u001b[K\rremote: Counting objects:  85% (52/61)\u001b[K\rremote: Counting objects:  86% (53/61)\u001b[K\rremote: Counting objects:  88% (54/61)\u001b[K\rremote: Counting objects:  90% (55/61)\u001b[K\rremote: Counting objects:  91% (56/61)\u001b[K\rremote: Counting objects:  93% (57/61)\u001b[K\rremote: Counting objects:  95% (58/61)\u001b[K\rremote: Counting objects:  96% (59/61)\u001b[K\rremote: Counting objects:  98% (60/61)\u001b[K\rremote: Counting objects: 100% (61/61)\u001b[K\rremote: Counting objects: 100% (61/61), done.\u001b[K\n",
            "remote: Compressing objects:   2% (1/41)\u001b[K\rremote: Compressing objects:   4% (2/41)\u001b[K\rremote: Compressing objects:   7% (3/41)\u001b[K\rremote: Compressing objects:   9% (4/41)\u001b[K\rremote: Compressing objects:  12% (5/41)\u001b[K\rremote: Compressing objects:  14% (6/41)\u001b[K\rremote: Compressing objects:  17% (7/41)\u001b[K\rremote: Compressing objects:  19% (8/41)\u001b[K\rremote: Compressing objects:  21% (9/41)\u001b[K\rremote: Compressing objects:  24% (10/41)\u001b[K\rremote: Compressing objects:  26% (11/41)\u001b[K\rremote: Compressing objects:  29% (12/41)\u001b[K\rremote: Compressing objects:  31% (13/41)\u001b[K\rremote: Compressing objects:  34% (14/41)\u001b[K\rremote: Compressing objects:  36% (15/41)\u001b[K\rremote: Compressing objects:  39% (16/41)\u001b[K\rremote: Compressing objects:  41% (17/41)\u001b[K\rremote: Compressing objects:  43% (18/41)\u001b[K\rremote: Compressing objects:  46% (19/41)\u001b[K\rremote: Compressing objects:  48% (20/41)\u001b[K\rremote: Compressing objects:  51% (21/41)\u001b[K\rremote: Compressing objects:  53% (22/41)\u001b[K\rremote: Compressing objects:  56% (23/41)\u001b[K\rremote: Compressing objects:  58% (24/41)\u001b[K\rremote: Compressing objects:  60% (25/41)\u001b[K\rremote: Compressing objects:  63% (26/41)\u001b[K\rremote: Compressing objects:  65% (27/41)\u001b[K\rremote: Compressing objects:  68% (28/41)\u001b[K\rremote: Compressing objects:  70% (29/41)\u001b[K\rremote: Compressing objects:  73% (30/41)\u001b[K\rremote: Compressing objects:  75% (31/41)\u001b[K\rremote: Compressing objects:  78% (32/41)\u001b[K\rremote: Compressing objects:  80% (33/41)\u001b[K\rremote: Compressing objects:  82% (34/41)\u001b[K\rremote: Compressing objects:  85% (35/41)\u001b[K\rremote: Compressing objects:  87% (36/41)\u001b[K\rremote: Compressing objects:  90% (37/41)\u001b[K\rremote: Compressing objects:  92% (38/41)\u001b[K\rremote: Compressing objects:  95% (39/41)\u001b[K\rremote: Compressing objects:  97% (40/41)\u001b[K\rremote: Compressing objects: 100% (41/41)\u001b[K\rremote: Compressing objects: 100% (41/41), done.\u001b[K\n",
            "Receiving objects:   0% (1/215)\rReceiving objects:   1% (3/215)\rReceiving objects:   2% (5/215)\rReceiving objects:   3% (7/215)\rReceiving objects:   4% (9/215)\rReceiving objects:   5% (11/215)\rReceiving objects:   6% (13/215)\rReceiving objects:   7% (16/215)\rReceiving objects:   8% (18/215)\rReceiving objects:   9% (20/215)\rReceiving objects:  10% (22/215)\rReceiving objects:  11% (24/215)\rReceiving objects:  12% (26/215)\rReceiving objects:  13% (28/215)\rReceiving objects:  14% (31/215)\rReceiving objects:  15% (33/215)\rReceiving objects:  16% (35/215)\rReceiving objects:  17% (37/215)\rReceiving objects:  18% (39/215)\rReceiving objects:  19% (41/215)\rReceiving objects:  20% (43/215)\rReceiving objects:  21% (46/215)\rReceiving objects:  22% (48/215)\rReceiving objects:  23% (50/215)\rReceiving objects:  24% (52/215)\rReceiving objects:  25% (54/215)\rReceiving objects:  26% (56/215)\rReceiving objects:  27% (59/215)\rReceiving objects:  28% (61/215)\rReceiving objects:  29% (63/215)\rReceiving objects:  30% (65/215)\rReceiving objects:  31% (67/215)\rReceiving objects:  32% (69/215)\rReceiving objects:  33% (71/215)\rReceiving objects:  34% (74/215)\rReceiving objects:  35% (76/215)\rReceiving objects:  36% (78/215)\rReceiving objects:  37% (80/215)\rReceiving objects:  38% (82/215)\rReceiving objects:  39% (84/215)\rReceiving objects:  40% (86/215)\rReceiving objects:  41% (89/215)\rReceiving objects:  42% (91/215)\rReceiving objects:  43% (93/215)\rReceiving objects:  44% (95/215)\rReceiving objects:  45% (97/215)\rReceiving objects:  46% (99/215)\rReceiving objects:  47% (102/215)\rReceiving objects:  48% (104/215)\rReceiving objects:  49% (106/215)\rReceiving objects:  50% (108/215)\rReceiving objects:  51% (110/215)\rReceiving objects:  52% (112/215)\rReceiving objects:  53% (114/215)\rReceiving objects:  54% (117/215)\rReceiving objects:  55% (119/215)\rReceiving objects:  56% (121/215)\rReceiving objects:  57% (123/215)\rReceiving objects:  58% (125/215)\rReceiving objects:  59% (127/215)\rReceiving objects:  60% (129/215)\rReceiving objects:  61% (132/215)\rReceiving objects:  62% (134/215)\rReceiving objects:  63% (136/215)\rReceiving objects:  64% (138/215)\rReceiving objects:  65% (140/215)\rReceiving objects:  66% (142/215)\rReceiving objects:  67% (145/215)\rReceiving objects:  68% (147/215)\rReceiving objects:  69% (149/215)\rReceiving objects:  70% (151/215)\rReceiving objects:  71% (153/215)\rReceiving objects:  72% (155/215)\rremote: Total 215 (delta 39), reused 34 (delta 20), pack-reused 154\u001b[K\n",
            "Receiving objects:  73% (157/215)\rReceiving objects:  74% (160/215)\rReceiving objects:  75% (162/215)\rReceiving objects:  76% (164/215)\rReceiving objects:  77% (166/215)\rReceiving objects:  78% (168/215)\rReceiving objects:  79% (170/215)\rReceiving objects:  80% (172/215)\rReceiving objects:  81% (175/215)\rReceiving objects:  82% (177/215)\rReceiving objects:  83% (179/215)\rReceiving objects:  84% (181/215)\rReceiving objects:  85% (183/215)\rReceiving objects:  86% (185/215)\rReceiving objects:  87% (188/215)\rReceiving objects:  88% (190/215)\rReceiving objects:  89% (192/215)\rReceiving objects:  90% (194/215)\rReceiving objects:  91% (196/215)\rReceiving objects:  92% (198/215)\rReceiving objects:  93% (200/215)\rReceiving objects:  94% (203/215)\rReceiving objects:  95% (205/215)\rReceiving objects:  96% (207/215)\rReceiving objects:  97% (209/215)\rReceiving objects:  98% (211/215)\rReceiving objects:  99% (213/215)\rReceiving objects: 100% (215/215)\rReceiving objects: 100% (215/215), 126.90 KiB | 21.15 MiB/s, done.\n",
            "Resolving deltas:   0% (0/101)\rResolving deltas:   1% (2/101)\rResolving deltas:   7% (8/101)\rResolving deltas:  13% (14/101)\rResolving deltas:  21% (22/101)\rResolving deltas:  23% (24/101)\rResolving deltas:  30% (31/101)\rResolving deltas:  45% (46/101)\rResolving deltas:  46% (47/101)\rResolving deltas:  47% (48/101)\rResolving deltas:  50% (51/101)\rResolving deltas:  55% (56/101)\rResolving deltas:  56% (57/101)\rResolving deltas:  59% (60/101)\rResolving deltas:  60% (61/101)\rResolving deltas:  65% (66/101)\rResolving deltas:  73% (74/101)\rResolving deltas:  86% (87/101)\rResolving deltas:  89% (90/101)\rResolving deltas:  98% (99/101)\rResolving deltas:  99% (100/101)\rResolving deltas: 100% (101/101)\rResolving deltas: 100% (101/101), done.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-9315e3d105f2>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mde_env\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mURRobotPusherGym\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mde_engine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mde_engine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDeepExplorationEngine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/./Sensorimotor_Learning_Final/deepexploration/de_engine.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0measyrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave_traj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdeepexploration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrun_inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdeepexploration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0meval_agent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'deepexploration'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "gmdo8YtM-Rsg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_configs(exp_name='bc'):\n",
        "    set_config('ppo')\n",
        "    cfg.alg.seed = 2 #seed\n",
        "    cfg.alg.num_envs = 1\n",
        "    cfg.alg.episode_steps = 150\n",
        "    cfg.alg.max_steps = 600000\n",
        "    cfg.alg.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    cfg.alg.env_name = 'URPusher-v1'\n",
        "    cfg.alg.save_dir = Path.cwd().absolute().joinpath('data').as_posix()\n",
        "    cfg.alg.save_dir += f'/{exp_name}'\n",
        "    setattr(cfg.alg, 'diff_cfg', dict(save_dir=cfg.alg.save_dir))\n",
        "\n",
        "    print(f'====================================')\n",
        "    print(f'      Device:{cfg.alg.device}')\n",
        "    print(f'====================================')"
      ],
      "metadata": {
        "id": "ygOfylf56eXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6GHT8Bu6854j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# env = make_vec_env(cfg.alg.env_name, cfg.alg.num_envs, seed=cfg.alg.seed)"
      ],
      "metadata": {
        "id": "0sNndyy-6hBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "5Z1xlQ5V-WDr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Runner Tests\n",
        "set_configs()\n",
        "env = URRobotPusherGym()\n",
        "\n",
        "critics = []\n",
        "for index in range(4):\n",
        "  ob_size = env.observation_space.shape[0]\n",
        "  critic_body = MLP(input_size=ob_size,\n",
        "                     hidden_sizes=[64],\n",
        "                     output_size=64,\n",
        "                     hidden_act=nn.Tanh,\n",
        "                     output_act=nn.Tanh)\n",
        "  critic = ValueNet(critic_body, in_features=64)\n",
        "  critics.append(critic)\n",
        "\n",
        "actor = create_actor(env=env)\n",
        "agent = DeepExplorationAgent(actor=actor, critics=critics, env=env)\n",
        "runner = DeepExplorationRunner(agent=agent, env=env)\n",
        "\n",
        "traj = runner(time_steps=cfg.alg.episode_steps)"
      ],
      "metadata": {
        "id": "aJ-EgxnK6vPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_de(max_steps=200000):\n",
        "    set_config('de')\n",
        "    cfg.alg.num_envs = 1\n",
        "    cfg.alg.episode_steps = 100\n",
        "    cfg.alg.max_steps = max_steps\n",
        "    cfg.alg.deque_size = 20\n",
        "    cfg.alg.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    cfg.alg.env_name = 'URPusher-v1'\n",
        "    cfg.alg.save_dir = Path.cwd().absolute().joinpath('data').as_posix()\n",
        "    cfg.alg.save_dir += '/'\n",
        "    cfg.alg.save_dir += 'push'\n",
        "    setattr(cfg.alg, 'diff_cfg', dict(save_dir=cfg.alg.save_dir))\n",
        "\n",
        "    print(f'====================================')\n",
        "    print(f'      Device:{cfg.alg.device}')\n",
        "    print(f'      Total number of steps:{cfg.alg.max_steps}')\n",
        "    print(f'====================================')\n",
        "\n",
        "    set_random_seed(cfg.alg.seed)\n",
        "    env_kwargs=dict()\n",
        "    env = make_vec_env(cfg.alg.env_name,\n",
        "                       cfg.alg.num_envs,\n",
        "                       seed=cfg.alg.seed,\n",
        "                       env_kwargs=env_kwargs)\n",
        "    env.reset()\n",
        "    ob_size = env.observation_space.shape[0]\n",
        "\n",
        "    actor_body = MLP(input_size=ob_size,\n",
        "                     hidden_sizes=[64],\n",
        "                     output_size=64,\n",
        "                     hidden_act=nn.Tanh,\n",
        "                     output_act=nn.Tanh)\n",
        "\n",
        "    critic_body = MLP(input_size=ob_size,\n",
        "                     hidden_sizes=[64],\n",
        "                     output_size=64,\n",
        "                     hidden_act=nn.Tanh,\n",
        "                     output_act=nn.Tanh)\n",
        "  \n",
        "    if isinstance(env.action_space, gym.spaces.Discrete):\n",
        "        act_size = env.action_space.n\n",
        "        actor = CategoricalPolicy(actor_body,\n",
        "                                 in_features=64,\n",
        "                                 action_dim=act_size)\n",
        "        \n",
        "    elif isinstance(env.action_space, gym.spaces.Box):\n",
        "        act_size = env.action_space.shape[0]\n",
        "        actor = DiagGaussianPolicy(actor_body,\n",
        "                                   in_features=64,\n",
        "                                   action_dim=act_size,\n",
        "                                   tanh_on_dist=cfg.alg.tanh_on_dist,\n",
        "                                   std_cond_in=cfg.alg.std_cond_in)\n",
        "    else:\n",
        "        raise TypeError(f'Unknown action space type: {env.action_space}')\n",
        "\n",
        "    # critics = [] ValueNet(critic_body, in_features=64) # TODO: get critics\n",
        "\n",
        "    for critic in range(5):\n",
        "      critics.append(create_critic(env))\n",
        "\n",
        "\n",
        "    agent = DeepExplorationAgent(actor=actor, critics=critics, env=env)\n",
        "    runner = DeepExplorationRunner(agent=agent, env=env)\n",
        "    engine = DeepExplorationEngine(agent=agent, runner=runner)\n",
        "    engine.train()\n",
        "    stat_info, raw_traj_info = engine.eval(render=False, save_eval_traj=True, eval_num=1, sleep_time=0.0)\n",
        "    pprint.pprint(stat_info)\n",
        "    return cfg.alg.save_dir"
      ],
      "metadata": {
        "id": "L7VVr1sV2T_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "saved_dir_pusher = train_de(max_steps = 1000000)"
      ],
      "metadata": {
        "id": "wWzzqcui5mAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "eFF3Pnnp5VqB"
      }
    }
  ]
}