{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNeRmLjS/X2vU3/4QxUWmdj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ppfenninger/Sensorimotor_Learning_Final/blob/main/Sensorimotor_Testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ruqTIwpD5vnR"
      },
      "outputs": [],
      "source": [
        "## Installation\n",
        "!pip install pybullet > /dev/null 2>&1\n",
        "!pip install git+https://github.com/taochenshh/easyrl.git > /dev/null 2>&1\n",
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "!pip install git+https://github.com/ppfenninger/airobot.git > /dev/null 2>&1\n",
        "# !pip install git+https://github.com/ppfenninger/Sensorimotor_Learning_Final.git > /dev/null 2>&1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import gym\n",
        "import pprint\n",
        "import time\n",
        "import pybullet as p\n",
        "import pybullet_data as pd\n",
        "import pybullet_envs\n",
        "import airobot as ar\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from typing import Any\n",
        "from matplotlib import animation\n",
        "from IPython.display import HTML\n",
        "from matplotlib import pylab\n",
        "from dataclasses import dataclass\n",
        "from gym import spaces\n",
        "from gym.envs.registration import registry, register\n",
        "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
        "from tqdm.notebook import tqdm\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from pathlib import Path\n",
        "from copy import deepcopy\n",
        "from itertools import count\n",
        "from easyrl.agents.ppo_agent import PPOAgent\n",
        "from easyrl.utils.common import save_traj\n",
        "from easyrl.configs import cfg\n",
        "from easyrl.configs import set_config\n",
        "from easyrl.configs.command_line import cfg_from_cmd\n",
        "from easyrl.engine.ppo_engine import PPOEngine\n",
        "from easyrl.models.categorical_policy import CategoricalPolicy\n",
        "from easyrl.models.diag_gaussian_policy import DiagGaussianPolicy\n",
        "from easyrl.models.mlp import MLP\n",
        "from easyrl.models.value_net import ValueNet\n",
        "from easyrl.agents.base_agent import BaseAgent\n",
        "from easyrl.utils.torch_util import DictDataset\n",
        "from easyrl.utils.torch_util import load_state_dict\n",
        "from easyrl.utils.torch_util import load_torch_model\n",
        "from easyrl.runner.nstep_runner import EpisodicRunner\n",
        "from easyrl.utils.torch_util import save_model\n",
        "from easyrl.utils.torch_util import action_entropy\n",
        "from easyrl.utils.torch_util import action_from_dist\n",
        "from easyrl.utils.torch_util import action_log_prob\n",
        "from easyrl.utils.torch_util import clip_grad\n",
        "from easyrl.utils.common import set_random_seed\n",
        "from easyrl.utils.gym_util import make_vec_env\n",
        "from easyrl.utils.common import load_from_json\n",
        "from easyrl.utils.torch_util import freeze_model\n",
        "from easyrl.utils.torch_util import move_to\n",
        "from easyrl.utils.torch_util import torch_float\n",
        "from easyrl.utils.torch_util import torch_to_np\n",
        "from base64 import b64encode\n",
        "from IPython import display as ipythondisplay"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qE3jrtj51tg",
        "outputId": "4ef8060a-9c7c-4ff3-e69d-bd2b24d776b7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:440: UserWarning: \u001b[33mWARN: The `registry.env_specs` property along with `EnvSpecTree` is deprecated. Please use `registry` directly as a dictionary instead.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/easyrl/envs/shmem_vec_env.py:23: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  np.bool: ctypes.c_bool}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# del sys.modules[\"de_agent\"]\n",
        "# del sys.modules[\"de_runner\"]\n",
        "# del sys.modules[\"utils\"]\n",
        "# del sys.modules[\"de_env\"]\n",
        "\n",
        "# install our library\n",
        "!rm Sensorimotor_Learning_Final -r\n",
        "!git clone https://github.com/ppfenninger/Sensorimotor_Learning_Final.git\n",
        "import sys\n",
        "sys.path.insert(0, './Sensorimotor_Learning_Final/deepexploration/')\n",
        "import de_agent\n",
        "from de_agent import DeepExplorationAgent\n",
        "# import de_engine\n",
        "import de_runner # this should work once everything compiles\n",
        "from de_runner import DeepExplorationRunner\n",
        "import utils\n",
        "from utils import generate_demonstration_data, eval_agent, load_expert_agent, create_actor\n",
        "\n",
        "import de_env\n",
        "from de_env import URRobotPusherGym\n",
        "\n",
        "import de_engine\n",
        "from de_engine import DeepExplorationEngine\n",
        "\n",
        "module_name = __name__\n",
        "\n",
        "env_name = 'URPusher-v1'\n",
        "if env_name in registry.env_specs:\n",
        "    del registry.env_specs[env_name]\n",
        "register(\n",
        "    id=env_name,\n",
        "    entry_point=f'{module_name}:URRobotPusherGym',\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFOrlFpX53Q6",
        "outputId": "ab39ab17-c650-47b7-ade9-fb287e4ad761"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Sensorimotor_Learning_Final'...\n",
            "remote: Enumerating objects: 208, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/54)\u001b[K\rremote: Counting objects:   3% (2/54)\u001b[K\rremote: Counting objects:   5% (3/54)\u001b[K\rremote: Counting objects:   7% (4/54)\u001b[K\rremote: Counting objects:   9% (5/54)\u001b[K\rremote: Counting objects:  11% (6/54)\u001b[K\rremote: Counting objects:  12% (7/54)\u001b[K\rremote: Counting objects:  14% (8/54)\u001b[K\rremote: Counting objects:  16% (9/54)\u001b[K\rremote: Counting objects:  18% (10/54)\u001b[K\rremote: Counting objects:  20% (11/54)\u001b[K\rremote: Counting objects:  22% (12/54)\u001b[K\rremote: Counting objects:  24% (13/54)\u001b[K\rremote: Counting objects:  25% (14/54)\u001b[K\rremote: Counting objects:  27% (15/54)\u001b[K\rremote: Counting objects:  29% (16/54)\u001b[K\rremote: Counting objects:  31% (17/54)\u001b[K\rremote: Counting objects:  33% (18/54)\u001b[K\rremote: Counting objects:  35% (19/54)\u001b[K\rremote: Counting objects:  37% (20/54)\u001b[K\rremote: Counting objects:  38% (21/54)\u001b[K\rremote: Counting objects:  40% (22/54)\u001b[K\rremote: Counting objects:  42% (23/54)\u001b[K\rremote: Counting objects:  44% (24/54)\u001b[K\rremote: Counting objects:  46% (25/54)\u001b[K\rremote: Counting objects:  48% (26/54)\u001b[K\rremote: Counting objects:  50% (27/54)\u001b[K\rremote: Counting objects:  51% (28/54)\u001b[K\rremote: Counting objects:  53% (29/54)\u001b[K\rremote: Counting objects:  55% (30/54)\u001b[K\rremote: Counting objects:  57% (31/54)\u001b[K\rremote: Counting objects:  59% (32/54)\u001b[K\rremote: Counting objects:  61% (33/54)\u001b[K\rremote: Counting objects:  62% (34/54)\u001b[K\rremote: Counting objects:  64% (35/54)\u001b[K\rremote: Counting objects:  66% (36/54)\u001b[K\rremote: Counting objects:  68% (37/54)\u001b[K\rremote: Counting objects:  70% (38/54)\u001b[K\rremote: Counting objects:  72% (39/54)\u001b[K\rremote: Counting objects:  74% (40/54)\u001b[K\rremote: Counting objects:  75% (41/54)\u001b[K\rremote: Counting objects:  77% (42/54)\u001b[K\rremote: Counting objects:  79% (43/54)\u001b[K\rremote: Counting objects:  81% (44/54)\u001b[K\rremote: Counting objects:  83% (45/54)\u001b[K\rremote: Counting objects:  85% (46/54)\u001b[K\rremote: Counting objects:  87% (47/54)\u001b[K\rremote: Counting objects:  88% (48/54)\u001b[K\rremote: Counting objects:  90% (49/54)\u001b[K\rremote: Counting objects:  92% (50/54)\u001b[K\rremote: Counting objects:  94% (51/54)\u001b[K\rremote: Counting objects:  96% (52/54)\u001b[K\rremote: Counting objects:  98% (53/54)\u001b[K\rremote: Counting objects: 100% (54/54)\u001b[K\rremote: Counting objects: 100% (54/54), done.\u001b[K\n",
            "remote: Compressing objects:   2% (1/35)\u001b[K\rremote: Compressing objects:   5% (2/35)\u001b[K\rremote: Compressing objects:   8% (3/35)\u001b[K\rremote: Compressing objects:  11% (4/35)\u001b[K\rremote: Compressing objects:  14% (5/35)\u001b[K\rremote: Compressing objects:  17% (6/35)\u001b[K\rremote: Compressing objects:  20% (7/35)\u001b[K\rremote: Compressing objects:  22% (8/35)\u001b[K\rremote: Compressing objects:  25% (9/35)\u001b[K\rremote: Compressing objects:  28% (10/35)\u001b[K\rremote: Compressing objects:  31% (11/35)\u001b[K\rremote: Compressing objects:  34% (12/35)\u001b[K\rremote: Compressing objects:  37% (13/35)\u001b[K\rremote: Compressing objects:  40% (14/35)\u001b[K\rremote: Compressing objects:  42% (15/35)\u001b[K\rremote: Compressing objects:  45% (16/35)\u001b[K\rremote: Compressing objects:  48% (17/35)\u001b[K\rremote: Compressing objects:  51% (18/35)\u001b[K\rremote: Compressing objects:  54% (19/35)\u001b[K\rremote: Compressing objects:  57% (20/35)\u001b[K\rremote: Compressing objects:  60% (21/35)\u001b[K\rremote: Compressing objects:  62% (22/35)\u001b[K\rremote: Compressing objects:  65% (23/35)\u001b[K\rremote: Compressing objects:  68% (24/35)\u001b[K\rremote: Compressing objects:  71% (25/35)\u001b[K\rremote: Compressing objects:  74% (26/35)\u001b[K\rremote: Compressing objects:  77% (27/35)\u001b[K\rremote: Compressing objects:  80% (28/35)\u001b[K\rremote: Compressing objects:  82% (29/35)\u001b[K\rremote: Compressing objects:  85% (30/35)\u001b[K\rremote: Compressing objects:  88% (31/35)\u001b[K\rremote: Compressing objects:  91% (32/35)\u001b[K\rremote: Compressing objects:  94% (33/35)\u001b[K\rremote: Compressing objects:  97% (34/35)\u001b[K\rremote: Compressing objects: 100% (35/35)\u001b[K\rremote: Compressing objects: 100% (35/35), done.\u001b[K\n",
            "Receiving objects:   0% (1/208)\rReceiving objects:   1% (3/208)\rReceiving objects:   2% (5/208)\rReceiving objects:   3% (7/208)\rReceiving objects:   4% (9/208)\rReceiving objects:   5% (11/208)\rReceiving objects:   6% (13/208)\rReceiving objects:   7% (15/208)\rReceiving objects:   8% (17/208)\rReceiving objects:   9% (19/208)\rReceiving objects:  10% (21/208)\rReceiving objects:  11% (23/208)\rReceiving objects:  12% (25/208)\rReceiving objects:  13% (28/208)\rReceiving objects:  14% (30/208)\rReceiving objects:  15% (32/208)\rReceiving objects:  16% (34/208)\rReceiving objects:  17% (36/208)\rReceiving objects:  18% (38/208)\rReceiving objects:  19% (40/208)\rReceiving objects:  20% (42/208)\rReceiving objects:  21% (44/208)\rReceiving objects:  22% (46/208)\rReceiving objects:  23% (48/208)\rReceiving objects:  24% (50/208)\rReceiving objects:  25% (52/208)\rReceiving objects:  26% (55/208)\rReceiving objects:  27% (57/208)\rReceiving objects:  28% (59/208)\rReceiving objects:  29% (61/208)\rReceiving objects:  30% (63/208)\rReceiving objects:  31% (65/208)\rReceiving objects:  32% (67/208)\rReceiving objects:  33% (69/208)\rReceiving objects:  34% (71/208)\rReceiving objects:  35% (73/208)\rReceiving objects:  36% (75/208)\rReceiving objects:  37% (77/208)\rReceiving objects:  38% (80/208)\rReceiving objects:  39% (82/208)\rReceiving objects:  40% (84/208)\rReceiving objects:  41% (86/208)\rReceiving objects:  42% (88/208)\rReceiving objects:  43% (90/208)\rReceiving objects:  44% (92/208)\rReceiving objects:  45% (94/208)\rReceiving objects:  46% (96/208)\rReceiving objects:  47% (98/208)\rReceiving objects:  48% (100/208)\rReceiving objects:  49% (102/208)\rReceiving objects:  50% (104/208)\rReceiving objects:  51% (107/208)\rReceiving objects:  52% (109/208)\rReceiving objects:  53% (111/208)\rReceiving objects:  54% (113/208)\rReceiving objects:  55% (115/208)\rReceiving objects:  56% (117/208)\rReceiving objects:  57% (119/208)\rReceiving objects:  58% (121/208)\rReceiving objects:  59% (123/208)\rReceiving objects:  60% (125/208)\rReceiving objects:  61% (127/208)\rReceiving objects:  62% (129/208)\rReceiving objects:  63% (132/208)\rReceiving objects:  64% (134/208)\rReceiving objects:  65% (136/208)\rReceiving objects:  66% (138/208)\rReceiving objects:  67% (140/208)\rReceiving objects:  68% (142/208)\rReceiving objects:  69% (144/208)\rReceiving objects:  70% (146/208)\rReceiving objects:  71% (148/208)\rReceiving objects:  72% (150/208)\rReceiving objects:  73% (152/208)\rReceiving objects:  74% (154/208)\rReceiving objects:  75% (156/208)\rReceiving objects:  76% (159/208)\rReceiving objects:  77% (161/208)\rReceiving objects:  78% (163/208)\rReceiving objects:  79% (165/208)\rReceiving objects:  80% (167/208)\rReceiving objects:  81% (169/208)\rReceiving objects:  82% (171/208)\rReceiving objects:  83% (173/208)\rReceiving objects:  84% (175/208)\rReceiving objects:  85% (177/208)\rReceiving objects:  86% (179/208)\rReceiving objects:  87% (181/208)\rReceiving objects:  88% (184/208)\rReceiving objects:  89% (186/208)\rremote: Total 208 (delta 34), reused 32 (delta 19), pack-reused 154\u001b[K\n",
            "Receiving objects:  90% (188/208)\rReceiving objects:  91% (190/208)\rReceiving objects:  92% (192/208)\rReceiving objects:  93% (194/208)\rReceiving objects:  94% (196/208)\rReceiving objects:  95% (198/208)\rReceiving objects:  96% (200/208)\rReceiving objects:  97% (202/208)\rReceiving objects:  98% (204/208)\rReceiving objects:  99% (206/208)\rReceiving objects: 100% (208/208)\rReceiving objects: 100% (208/208), 123.43 KiB | 12.34 MiB/s, done.\n",
            "Resolving deltas:   0% (0/96)\rResolving deltas:   2% (2/96)\rResolving deltas:   8% (8/96)\rResolving deltas:  14% (14/96)\rResolving deltas:  22% (22/96)\rResolving deltas:  26% (25/96)\rResolving deltas:  32% (31/96)\rResolving deltas:  47% (46/96)\rResolving deltas:  48% (47/96)\rResolving deltas:  51% (49/96)\rResolving deltas:  52% (50/96)\rResolving deltas:  57% (55/96)\rResolving deltas:  59% (57/96)\rResolving deltas:  61% (59/96)\rResolving deltas:  63% (61/96)\rResolving deltas:  68% (66/96)\rResolving deltas:  77% (74/96)\rResolving deltas:  87% (84/96)\rResolving deltas:  90% (87/96)\rResolving deltas:  97% (94/96)\rResolving deltas:  98% (95/96)\rResolving deltas: 100% (96/96)\rResolving deltas: 100% (96/96), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "gmdo8YtM-Rsg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_configs(exp_name='bc'):\n",
        "    set_config('ppo')\n",
        "    cfg.alg.seed = 2 #seed\n",
        "    cfg.alg.num_envs = 1\n",
        "    cfg.alg.episode_steps = 150\n",
        "    cfg.alg.max_steps = 600000\n",
        "    cfg.alg.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    cfg.alg.env_name = 'URPusher-v1'\n",
        "    cfg.alg.save_dir = Path.cwd().absolute().joinpath('data').as_posix()\n",
        "    cfg.alg.save_dir += f'/{exp_name}'\n",
        "    setattr(cfg.alg, 'diff_cfg', dict(save_dir=cfg.alg.save_dir))\n",
        "\n",
        "    print(f'====================================')\n",
        "    print(f'      Device:{cfg.alg.device}')\n",
        "    print(f'====================================')"
      ],
      "metadata": {
        "id": "ygOfylf56eXl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6GHT8Bu6854j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# env = make_vec_env(cfg.alg.env_name, cfg.alg.num_envs, seed=cfg.alg.seed)"
      ],
      "metadata": {
        "id": "0sNndyy-6hBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "5Z1xlQ5V-WDr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Runner Tests\n",
        "set_configs()\n",
        "env = URRobotPusherGym()\n",
        "\n",
        "critics = []\n",
        "for index in range(4):\n",
        "  ob_size = env.observation_space.shape[0]\n",
        "  critic_body = MLP(input_size=ob_size,\n",
        "                     hidden_sizes=[64],\n",
        "                     output_size=64,\n",
        "                     hidden_act=nn.Tanh,\n",
        "                     output_act=nn.Tanh)\n",
        "  critic = ValueNet(critic_body, in_features=64)\n",
        "  critics.append(critic)\n",
        "\n",
        "actor = create_actor(env=env)\n",
        "agent = DeepExplorationAgent(actor=actor, critics=critics, env=env)\n",
        "runner = DeepExplorationRunner(agent=agent, env=env)\n",
        "\n",
        "traj = runner(time_steps=cfg.alg.episode_steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJ-EgxnK6vPb",
        "outputId": "e4f70a19-60b2-4792-cd93-5951179b8428"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[INFO]\u001b[0m[2023-05-05 21:43:24]: \u001b[32mAlogrithm type:<class 'easyrl.configs.ppo_config.PPOConfig'>\u001b[0m\n",
            "INFO:EasyRL:Alogrithm type:<class 'easyrl.configs.ppo_config.PPOConfig'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================\n",
            "      Device:cpu\n",
            "====================================\n",
            "entering exploration more\n",
            "exiting exploration more\n",
            "entering exploration more\n",
            "exiting exploration more\n",
            "entering exploration more\n",
            "exiting exploration more\n",
            "entering exploration more\n",
            "exiting exploration more\n",
            "entering exploration more\n",
            "exiting exploration more\n",
            "entering exploration more\n",
            "exiting exploration more\n",
            "entering exploration more\n",
            "exiting exploration more\n",
            "entering exploration more\n",
            "exiting exploration more\n",
            "entering exploration more\n",
            "exiting exploration more\n",
            "entering exploration more\n",
            "exiting exploration more\n",
            "entering exploration more\n",
            "exiting exploration more\n",
            "entering exploration more\n",
            "exiting exploration more\n",
            "entering exploration more\n",
            "exiting exploration more\n",
            "entering exploration more\n",
            "exiting exploration more\n",
            "entering exploration more\n",
            "exiting exploration more\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_de(max_steps=200000):\n",
        "    set_config('de')\n",
        "    cfg.alg.num_envs = 1\n",
        "    cfg.alg.episode_steps = 100\n",
        "    cfg.alg.max_steps = max_steps\n",
        "    cfg.alg.deque_size = 20\n",
        "    cfg.alg.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    cfg.alg.env_name = 'URPusher-v1'\n",
        "    cfg.alg.save_dir = Path.cwd().absolute().joinpath('data').as_posix()\n",
        "    cfg.alg.save_dir += '/'\n",
        "    cfg.alg.save_dir += 'push'\n",
        "    setattr(cfg.alg, 'diff_cfg', dict(save_dir=cfg.alg.save_dir))\n",
        "\n",
        "    print(f'====================================')\n",
        "    print(f'      Device:{cfg.alg.device}')\n",
        "    print(f'      Total number of steps:{cfg.alg.max_steps}')\n",
        "    print(f'====================================')\n",
        "\n",
        "    set_random_seed(cfg.alg.seed)\n",
        "    env_kwargs=dict()\n",
        "    env = make_vec_env(cfg.alg.env_name,\n",
        "                       cfg.alg.num_envs,\n",
        "                       seed=cfg.alg.seed,\n",
        "                       env_kwargs=env_kwargs)\n",
        "    env.reset()\n",
        "    ob_size = env.observation_space.shape[0]\n",
        "\n",
        "    actor_body = MLP(input_size=ob_size,\n",
        "                     hidden_sizes=[64],\n",
        "                     output_size=64,\n",
        "                     hidden_act=nn.Tanh,\n",
        "                     output_act=nn.Tanh)\n",
        "\n",
        "    critic_body = MLP(input_size=ob_size,\n",
        "                     hidden_sizes=[64],\n",
        "                     output_size=64,\n",
        "                     hidden_act=nn.Tanh,\n",
        "                     output_act=nn.Tanh)\n",
        "  \n",
        "    if isinstance(env.action_space, gym.spaces.Discrete):\n",
        "        act_size = env.action_space.n\n",
        "        actor = CategoricalPolicy(actor_body,\n",
        "                                 in_features=64,\n",
        "                                 action_dim=act_size)\n",
        "        \n",
        "    elif isinstance(env.action_space, gym.spaces.Box):\n",
        "        act_size = env.action_space.shape[0]\n",
        "        actor = DiagGaussianPolicy(actor_body,\n",
        "                                   in_features=64,\n",
        "                                   action_dim=act_size,\n",
        "                                   tanh_on_dist=cfg.alg.tanh_on_dist,\n",
        "                                   std_cond_in=cfg.alg.std_cond_in)\n",
        "    else:\n",
        "        raise TypeError(f'Unknown action space type: {env.action_space}')\n",
        "\n",
        "    critics = ValueNet(critic_body, in_features=64) # TODO: get critics\n",
        "    agent = DeepExplorationAgent(actor=actor, critic=critic, env=env)\n",
        "    runner = DeepExplorationRunner(agent=agent, env=env)\n",
        "    engine = DeepExplorationEngine(agent=agent, runner=runner)\n",
        "    engine.train()\n",
        "    stat_info, raw_traj_info = engine.eval(render=False, save_eval_traj=True, eval_num=1, sleep_time=0.0)\n",
        "    pprint.pprint(stat_info)\n",
        "    return cfg.alg.save_dir"
      ],
      "metadata": {
        "id": "L7VVr1sV2T_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "eFF3Pnnp5VqB"
      }
    }
  ]
}